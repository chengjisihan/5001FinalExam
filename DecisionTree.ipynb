{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['E', 'A', 'N', 1, 20, 'H'],\n",
       "       ['N', 'D', 'D', 2, 20, 'H'],\n",
       "       ['N', 'D', 'P', 2, 20, 'M'],\n",
       "       ['N', 'B', 'D', 2, 50, 'L'],\n",
       "       ['N', 'D', 'P', 2, 30, 'H'],\n",
       "       ['N', 'A', 'N', 1, 30, 'H'],\n",
       "       ['N', 'A', 'D', 2, 10, 'L'],\n",
       "       ['N', 'D', 'P', 2, 20, 'M'],\n",
       "       ['N', 'A', 'N', 1, 20, 'M'],\n",
       "       ['N', 'B', 'A', 2, 40, 'M'],\n",
       "       ['E', 'A', 'N', 2, 40, 'L'],\n",
       "       ['E', 'D', 'D', 1, 10, 'L'],\n",
       "       ['N', 'B', 'P', 2, 40, 'M'],\n",
       "       ['E', 'B', 'A', 2, 30, 'M'],\n",
       "       ['E', 'D', 'A', 2, 50, 'H'],\n",
       "       ['N', 'B', 'N', 2, 50, 'M'],\n",
       "       ['E', 'B', 'D', 1, 50, 'H'],\n",
       "       ['N', 'D', 'A', 1, 10, 'M'],\n",
       "       ['E', 'A', 'N', 2, 30, 'L'],\n",
       "       ['N', 'A', 'P', 1, 20, 'M']], dtype=object)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data\n",
    "dataFrame = pd.read_csv(\"TADocuments.csv\")\n",
    "dataFrame = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['N', 'E'],\n",
       " ['A', 'B', 'D'],\n",
       " ['N', 'D', 'A', 'P'],\n",
       " [1, 2],\n",
       " [10, 20, 30, 40, 50]]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preset attribute and value vectors\n",
    "valueFrame = [['N', 'E'],['A', 'B', 'D'],['N', 'D', 'A', 'P'],[1, 2],[10, 20, 30, 40, 50]]\n",
    "attributes = [0, 1, 2, 3, 4]\n",
    "attribute = ['Language', 'Instructor', 'Course', 'Semester', 'ClassSize']\n",
    "valueFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select attribute for dividing the dataset using ID3, return divided dataset and attribute index\n",
    "def SelectAttributeID3(dataset, valueset, attributes, n):\n",
    "    high = 0;\n",
    "    middle = 0;\n",
    "    low = 0;\n",
    "    entropy1 = 0;\n",
    "    entropy2 = 0;\n",
    "    entropy3 = 0;\n",
    "    entropy = [0, 0, 0, 0, 0]\n",
    "    totalnum = 0;\n",
    "    suma = 0\n",
    "    count = [0, 0, 0, 0, 0]\n",
    "    infoGain = [0, 0, 0, 0, 0]\n",
    "    totalEntropy = 0\n",
    "    j = -1\n",
    "    subsetotal = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        if (item[5] == 'H'):\n",
    "            high += 1\n",
    "        elif (item[5] == 'M'):\n",
    "            middle += 1\n",
    "        elif (item[5] == 'L'):\n",
    "            low += 1\n",
    "    high += 0.0\n",
    "    middle += 0.0\n",
    "    low += 0.0\n",
    "    totalnum = high + middle + low\n",
    "    if(high == 0):\n",
    "        entropy1 = 0\n",
    "    else:\n",
    "        entropy1 = -(high/totalnum)*log(high/totalnum, 2)\n",
    "    if(middle == 0):\n",
    "        entropy2 = 0\n",
    "    else:\n",
    "        entropy2 = -(middle/totalnum)*log(middle/totalnum, 2)\n",
    "    if(low == 0):\n",
    "        entropy3 = 0\n",
    "    else:\n",
    "        entropy3 = -(low/totalnum)*log(low/totalnum, 2)\n",
    "    entropy0 = entropy1+entropy2+entropy3\n",
    "    print \"Entropy before is %f\"%entropy0\n",
    "    if(entropy0 == 0):\n",
    "        print \"This tree has reached its leaf\"\n",
    "        return 0,0,[]\n",
    "        \n",
    "    high, middle, low, totalnum = 0, 0, 0, 0\n",
    "    \n",
    "    print valueset\n",
    "    for i in range(n):\n",
    "        #subset = []\n",
    "        #print i\n",
    "        for value in valueset[i]:\n",
    "            #print value\n",
    "            j += 1\n",
    "            subsetpartial = []\n",
    "            for item in dataset:\n",
    "                #print item[attributes[i]]\n",
    "                if (item[attributes[i]] == value):\n",
    "                    subsetpartial.append(item)\n",
    "                    if (item[5] == 'H'):\n",
    "                        high += 1\n",
    "                    elif (item[5] == 'M'):\n",
    "                        middle += 1\n",
    "                    elif (item[5] == 'L'):\n",
    "                        low += 1\n",
    "            if(len(subsetpartial) == 0):\n",
    "                break\n",
    "            #subset.append(subsetpartial)\n",
    "            high += 0.0\n",
    "            middle += 0.0\n",
    "            low += 0.0\n",
    "            totalnum = high + middle + low\n",
    "            #print \"totalnum:%f\"%totalnum\n",
    "            if(high == 0):\n",
    "                entropy1 = 0\n",
    "            else:\n",
    "                entropy1 = -(high/totalnum)*log(high/totalnum, 2)\n",
    "            if(middle == 0):\n",
    "                entropy2 = 0\n",
    "            else:\n",
    "                entropy2 = -(middle/totalnum)*log(middle/totalnum, 2)\n",
    "            if(low == 0):\n",
    "                entropy3 = 0\n",
    "            else:\n",
    "                entropy3 = -(low/totalnum)*log(low/totalnum, 2)\n",
    "            entropy[j] = entropy1 + entropy2 + entropy3\n",
    "            #print \"entropy of this value is %f\"%entropy[j]\n",
    "            entropy1, entropy2, entropy3 = 0, 0, 0\n",
    "            count[j] = totalnum\n",
    "            totalEntropy = (totalEntropy+0.0) + (totalnum/(len(dataset)+0.0))*entropy[j]\n",
    "            high, middle, low, totalnum = 0, 0, 0, 0\n",
    "        #print \"total entropy is %f,dataset len is %d\"%(totalEntropy, len(dataset))\n",
    "        infoGain[i] = entropy0 - totalEntropy\n",
    "        print \"Information Gain is %f\"%infoGain[i]\n",
    "        j = -1\n",
    "        totalEntropy = 0\n",
    "        #subsetotal.append(subset)\n",
    "    \n",
    "    maxi = 0;\n",
    "    argmax = 0;\n",
    "    for i in range(n):\n",
    "        if(infoGain[i] >= maxi):\n",
    "            argmax = i\n",
    "            maxi = infoGain[i]\n",
    "    #print attributes\n",
    "    for value in valueset[argmax]:\n",
    "        subset = []\n",
    "        for item in dataset:\n",
    "            #print item[attributes[i]], value\n",
    "            if(item[attributes[argmax]] == value):\n",
    "                subset.append(item)\n",
    "        subsetotal.append(subset)\n",
    "    #print subsetotal\n",
    "        \n",
    "    print \"argmax is %d\\n\"%argmax\n",
    "    print \"We ought to choose attribute %s at this step, and infoGain = %f\\n\"%(attribute[attributes[argmax]], maxi)\n",
    "    return argmax, maxi, subsetotal\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select attribute for dividing the dataset using ID3, return divided dataset and attribute index\n",
    "def SelectAttributeC4(dataset, valueset, attributes, n):\n",
    "    high = 0;\n",
    "    middle = 0;\n",
    "    low = 0;\n",
    "    entropy1 = 0;\n",
    "    entropy2 = 0;\n",
    "    entropy3 = 0;\n",
    "    entropy = [0, 0, 0, 0, 0]\n",
    "    totalnum = 0;\n",
    "    suma = 0\n",
    "    count = [0, 0, 0, 0, 0]\n",
    "    infoGain = [0, 0, 0, 0, 0]\n",
    "    totalEntropy = 0\n",
    "    j = -1\n",
    "    subsetotal = []\n",
    "    splitInfo = 0\n",
    "    \n",
    "    for item in dataset:\n",
    "        if (item[5] == 'H'):\n",
    "            high += 1\n",
    "        elif (item[5] == 'M'):\n",
    "            middle += 1\n",
    "        elif (item[5] == 'L'):\n",
    "            low += 1\n",
    "    high += 0.0\n",
    "    middle += 0.0\n",
    "    low += 0.0\n",
    "    totalnum = high + middle + low\n",
    "    if(high == 0):\n",
    "        entropy1 = 0\n",
    "    else:\n",
    "        entropy1 = -(high/totalnum)*log(high/totalnum, 2)\n",
    "    if(middle == 0):\n",
    "        entropy2 = 0\n",
    "    else:\n",
    "        entropy2 = -(middle/totalnum)*log(middle/totalnum, 2)\n",
    "    if(low == 0):\n",
    "        entropy3 = 0\n",
    "    else:\n",
    "        entropy3 = -(low/totalnum)*log(low/totalnum, 2)\n",
    "    entropy0 = entropy1+entropy2+entropy3\n",
    "    print \"Entropy before is %f\"%entropy0\n",
    "    if(entropy0 == 0):\n",
    "        print \"This tree has reached its leaf\"\n",
    "        return 0,0,[]\n",
    "        \n",
    "    high, middle, low, totalnum = 0, 0, 0, 0\n",
    "    \n",
    "    print valueset\n",
    "    for i in range(n):\n",
    "        #subset = []\n",
    "        #print i\n",
    "        for value in valueset[i]:\n",
    "            #print value\n",
    "            j += 1\n",
    "            subsetpartial = []\n",
    "            for item in dataset:\n",
    "                #print item[attributes[i]]\n",
    "                if (item[attributes[i]] == value):\n",
    "                    subsetpartial.append(item)\n",
    "                    if (item[5] == 'H'):\n",
    "                        high += 1\n",
    "                    elif (item[5] == 'M'):\n",
    "                        middle += 1\n",
    "                    elif (item[5] == 'L'):\n",
    "                        low += 1\n",
    "            if(len(subsetpartial) == 0):\n",
    "                break\n",
    "            #subset.append(subsetpartial)\n",
    "            high += 0.0\n",
    "            middle += 0.0\n",
    "            low += 0.0\n",
    "            totalnum = high + middle + low\n",
    "            #print \"totalnum:%f\"%totalnum\n",
    "            if(high == 0):\n",
    "                entropy1 = 0\n",
    "            else:\n",
    "                entropy1 = -(high/totalnum)*log(high/totalnum, 2)\n",
    "            if(middle == 0):\n",
    "                entropy2 = 0\n",
    "            else:\n",
    "                entropy2 = -(middle/totalnum)*log(middle/totalnum, 2)\n",
    "            if(low == 0):\n",
    "                entropy3 = 0\n",
    "            else:\n",
    "                entropy3 = -(low/totalnum)*log(low/totalnum, 2)\n",
    "            entropy[j] = entropy1 + entropy2 + entropy3\n",
    "            #print \"entropy of this value is %f\"%entropy[j]\n",
    "            entropy1, entropy2, entropy3 = 0, 0, 0\n",
    "            count[j] = totalnum\n",
    "            totalEntropy = (totalEntropy+0.0) + (totalnum/(len(dataset)+0.0))*entropy[j]\n",
    "            splitInfo = splitInfo - (totalnum/len(dataset))*log(totalnum/len(dataset), 2)\n",
    "            high, middle, low, totalnum = 0, 0, 0, 0\n",
    "        #print \"total entropy is %f,dataset len is %d\"%(totalEntropy, len(dataset))\n",
    "        if(splitInfo == 0):\n",
    "            infoGain[i] = 0\n",
    "        else:\n",
    "            infoGain[i] = (entropy0 - totalEntropy)/splitInfo\n",
    "        print \"Information Gain is %f\"%infoGain[i]\n",
    "        j = -1\n",
    "        totalEntropy = 0\n",
    "        splitInfo = 0\n",
    "        #subsetotal.append(subset)\n",
    "    \n",
    "    maxi = 0;\n",
    "    argmax = 0;\n",
    "    for i in range(n):\n",
    "        if(infoGain[i] >= maxi):\n",
    "            argmax = i\n",
    "            maxi = infoGain[i]\n",
    "    #print attributes\n",
    "    for value in valueset[argmax]:\n",
    "        subset = []\n",
    "        for item in dataset:\n",
    "            #print item[attributes[i]], value\n",
    "            if(item[attributes[argmax]] == value):\n",
    "                subset.append(item)\n",
    "        subsetotal.append(subset)\n",
    "    #print subsetotal\n",
    "        \n",
    "    print \"argmax is %d\\n\"%argmax\n",
    "    print \"We ought to choose attribute %s at this step, and infoGain = %f\\n\"%(attribute[attributes[argmax]], maxi)\n",
    "    return argmax, maxi, subsetotal\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SelectAttributeC45(dataset, valueset, attributes, n):\n",
    "    high = 0;\n",
    "    middle = 0;\n",
    "    low = 0;\n",
    "    entropy1 = 0;\n",
    "    entropy2 = 0;\n",
    "    entropy3 = 0;\n",
    "    entropy = [0, 0, 0, 0, 0]\n",
    "    totalnum = 0;\n",
    "    suma = 0\n",
    "    count = [0, 0, 0, 0, 0]\n",
    "    infoGain = [0, 0, 0, 0, 0]\n",
    "    totalEntropy = 0\n",
    "    j = -1\n",
    "    subsetotal = []\n",
    "    splitInfo = 0\n",
    "    \n",
    "    for item in dataset:\n",
    "        if (item[5] == 'H'):\n",
    "            high += 1\n",
    "        elif (item[5] == 'M'):\n",
    "            middle += 1\n",
    "        elif (item[5] == 'L'):\n",
    "            low += 1\n",
    "    high += 0.0\n",
    "    middle += 0.0\n",
    "    low += 0.0\n",
    "    totalnum = high + middle + low\n",
    "    if(high == 0):\n",
    "        entropy1 = 0\n",
    "    else:\n",
    "        entropy1 = -(high/totalnum)*log(high/totalnum, 2)\n",
    "    if(middle == 0):\n",
    "        entropy2 = 0\n",
    "    else:\n",
    "        entropy2 = -(middle/totalnum)*log(middle/totalnum, 2)\n",
    "    if(low == 0):\n",
    "        entropy3 = 0\n",
    "    else:\n",
    "        entropy3 = -(low/totalnum)*log(low/totalnum, 2)\n",
    "    entropy0 = entropy1+entropy2+entropy3\n",
    "    print \"Entropy before is %f\"%entropy0\n",
    "    if(entropy0 == 0):\n",
    "        print \"This tree has reached its leaf\"\n",
    "        return 0,0,[]\n",
    "        \n",
    "    high, middle, low, totalnum = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        #subset = []\n",
    "        for value in valueset[i]:\n",
    "            #print value\n",
    "            j += 1\n",
    "            #subsetpartial = []\n",
    "            for item in dataset:\n",
    "                #print item[attributes[i]]\n",
    "                if (item[attributes[i]] == value):\n",
    "                    #subsetpartial.append(item)\n",
    "                    if (item[5] == 'H'):\n",
    "                        high += 1\n",
    "                    elif (item[5] == 'M'):\n",
    "                        middle += 1\n",
    "                    elif (item[5] == 'L'):\n",
    "                        low += 1\n",
    "            #if(len(subsetpartial) == 0):\n",
    "                #break\n",
    "            #subset.append(subsetpartial)\n",
    "            high += 0.0\n",
    "            middle += 0.0\n",
    "            low += 0.0\n",
    "            totalnum = high + middle + low\n",
    "            #print \"totalnum:%f\"%totalnum\n",
    "            if(high == 0):\n",
    "                entropy1 = 0\n",
    "            else:\n",
    "                entropy1 = -(high/totalnum)*log(high/totalnum, 2)\n",
    "            if(middle == 0):\n",
    "                entropy2 = 0\n",
    "            else:\n",
    "                entropy2 = -(middle/totalnum)*log(middle/totalnum, 2)\n",
    "            if(low == 0):\n",
    "                entropy3 = 0\n",
    "            else:\n",
    "                entropy3 = -(low/totalnum)*log(low/totalnum, 2)\n",
    "            entropy[j] = entropy1 + entropy2 + entropy3\n",
    "            #print \"entropy of this value is %f\"%entropy[j]\n",
    "            entropy1, entropy2, entropy3 = 0, 0, 0\n",
    "            count[j] = totalnum\n",
    "            totalEntropy = (totalEntropy+0.0) + (totalnum/(len(dataset)+0.0))*entropy[j]\n",
    "            splitInfo = splitInfo - (totalnum/len(dataset))*log(totalnum/len(dataset), 2)\n",
    "            high, middle, low, totalnum = 0, 0, 0, 0\n",
    "        #print \"total entropy is %f,dataset len is %d\"%(totalEntropy, len(dataset))\n",
    "        if(splitInfo == 0):\n",
    "            infoGain[i] = 0\n",
    "        else:\n",
    "            infoGain[i] = (entropy0 - totalEntropy)/splitInfo\n",
    "        print \"Information Gain is %f\"%infoGain[i]\n",
    "        j = -1\n",
    "        totalEntropy = 0\n",
    "        splitInfo = 0\n",
    "        #subsetotal.append(subset)\n",
    "    \n",
    "    maxi = 0;\n",
    "    argmax = 0;\n",
    "    for i in range(n):\n",
    "        if(infoGain[i] >= maxi):\n",
    "            argmax = i\n",
    "            maxi = infoGain[i]\n",
    "    \n",
    "    for value in valueset[argmax]:\n",
    "        subset = []\n",
    "        for item in dataset:\n",
    "            if(item[attributes[argmax]] == value):\n",
    "                subset.append(item)\n",
    "        subsetotal.append(subset)\n",
    "    \n",
    "    print \"argmax is %d\\n\"%argmax\n",
    "    print \"We ought to choose attribute %s at this step, and infoGain = %f\\n\"%(attribute[attributes[argmax]], maxi)\n",
    "    return argmax, maxi, subsetotal\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DecisionTreeID3(data, value, attributes, n):\n",
    "    subsetQueue = Queue.Queue()\n",
    "    subsetQueue.put(data)\n",
    "    while not subsetQueue.empty():\n",
    "        if(len(attributes) & len(value)):\n",
    "            dataset = subsetQueue.get()\n",
    "            argmax, maxi, subset = SelectAttributeID3(dataset, value, attributes, n)\n",
    "            if((argmax == 0) & (maxi == 0.0)):\n",
    "                print \"Reach leaf node at DecisionTree!\"\n",
    "                continue\n",
    "            else:\n",
    "                for semiset in subset:\n",
    "                    subsetQueue.put(semiset)\n",
    "                del value[argmax]\n",
    "                attributes = np.delete(attributes, argmax)\n",
    "                print attributes\n",
    "                n = n - 1\n",
    "        else:\n",
    "            break\n",
    "    return 0\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DTID3(data, value, attributes, n):\n",
    "    print \"depth is %d\"%(5-n)\n",
    "    print data\n",
    "    argmax, maxi, subset = SelectAttributeID3(data, value, attributes, n)\n",
    "    #print subset\n",
    "    valued = value[:]\n",
    "    del valued[argmax]\n",
    "    for item in subset:\n",
    "        #print item\n",
    "        attr = attributes\n",
    "        DTID3(item, valued, np.delete(attr, argmax), n-1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DTC4(data, value, attributes, n):\n",
    "    print \"depth is %d\"%(5-n)\n",
    "    print data\n",
    "    argmax, maxi, subset = SelectAttributeC4(data, value, attributes, n)\n",
    "    #print subset\n",
    "    valued = value[:]\n",
    "    del valued[argmax]\n",
    "    for item in subset:\n",
    "        #print item\n",
    "        attr = attributes\n",
    "        DTID3(item, valued, np.delete(attr, argmax), n-1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DecisionTreeC45(data, value, attributes, n):\n",
    "    subsetQueue = Queue.Queue()\n",
    "    subsetQueue.put(data)\n",
    "    while not subsetQueue.empty():\n",
    "        if(len(attributes) & len(value)):\n",
    "            dataset = subsetQueue.get()\n",
    "            argmax, maxi, subset = SelectAttributeC45(dataset, value, attributes, n)\n",
    "            if((argmax == 0) & (maxi == 0.0)):\n",
    "                print \"Reach leaf node at DecisionTree!\"\n",
    "                continue\n",
    "            else:\n",
    "                for semiset in subset:\n",
    "                    subsetQueue.put(semiset)\n",
    "                del value[argmax]\n",
    "                attributes = np.delete(attributes, argmax)\n",
    "                print attributes\n",
    "                n = n - 1\n",
    "        else:\n",
    "            break\n",
    "    return 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth is 0\n",
      "[['E' 'A' 'N' 1 20 'H']\n",
      " ['N' 'D' 'D' 2 20 'H']\n",
      " ['N' 'D' 'P' 2 20 'M']\n",
      " ['N' 'B' 'D' 2 50 'L']\n",
      " ['N' 'D' 'P' 2 30 'H']\n",
      " ['N' 'A' 'N' 1 30 'H']\n",
      " ['N' 'A' 'D' 2 10 'L']\n",
      " ['N' 'D' 'P' 2 20 'M']\n",
      " ['N' 'A' 'N' 1 20 'M']\n",
      " ['N' 'B' 'A' 2 40 'M']\n",
      " ['E' 'A' 'N' 2 40 'L']\n",
      " ['E' 'D' 'D' 1 10 'L']\n",
      " ['N' 'B' 'P' 2 40 'M']\n",
      " ['E' 'B' 'A' 2 30 'M']\n",
      " ['E' 'D' 'A' 2 50 'H']\n",
      " ['N' 'B' 'N' 2 50 'M']\n",
      " ['E' 'B' 'D' 1 50 'H']\n",
      " ['N' 'D' 'A' 1 10 'M']\n",
      " ['E' 'A' 'N' 2 30 'L']\n",
      " ['N' 'A' 'P' 1 20 'M']]\n",
      "Entropy before is 1.539491\n",
      "[['N', 'E'], ['A', 'B', 'D'], ['N', 'D', 'A', 'P'], [1, 2], [10, 20, 30, 40, 50]]\n",
      "Information Gain is 0.176501\n",
      "Information Gain is 0.070883\n",
      "Information Gain is 0.241014\n",
      "Information Gain is 0.043201\n",
      "Information Gain is 0.171080\n",
      "argmax is 2\n",
      "\n",
      "We ought to choose attribute Course at this step, and infoGain = 0.241014\n",
      "\n",
      "depth is 1\n",
      "[array(['E', 'A', 'N', 1, 20, 'H'], dtype=object), array(['N', 'A', 'N', 1, 30, 'H'], dtype=object), array(['N', 'A', 'N', 1, 20, 'M'], dtype=object), array(['E', 'A', 'N', 2, 40, 'L'], dtype=object), array(['N', 'B', 'N', 2, 50, 'M'], dtype=object), array(['E', 'A', 'N', 2, 30, 'L'], dtype=object)]\n",
      "Entropy before is 1.584963\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2], [10, 20, 30, 40, 50]]\n",
      "Information Gain is 0.666667\n",
      "Information Gain is 0.316689\n",
      "Information Gain is 0.666667\n",
      "Information Gain is 1.584963\n",
      "argmax is 3\n",
      "\n",
      "We ought to choose attribute ClassSize at this step, and infoGain = 1.584963\n",
      "\n",
      "depth is 2\n",
      "[]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['E', 'A', 'N', 1, 20, 'H'], dtype=object), array(['N', 'A', 'N', 1, 20, 'M'], dtype=object)]\n",
      "Entropy before is 1.000000\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2]]\n",
      "Information Gain is 1.000000\n",
      "Information Gain is 0.000000\n",
      "Information Gain is 0.000000\n",
      "argmax is 0\n",
      "\n",
      "We ought to choose attribute Language at this step, and infoGain = 1.000000\n",
      "\n",
      "depth is 3\n",
      "[array(['N', 'A', 'N', 1, 20, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 3\n",
      "[array(['E', 'A', 'N', 1, 20, 'H'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'A', 'N', 1, 30, 'H'], dtype=object), array(['E', 'A', 'N', 2, 30, 'L'], dtype=object)]\n",
      "Entropy before is 1.000000\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2]]\n",
      "Information Gain is 1.000000\n",
      "Information Gain is 0.000000\n",
      "Information Gain is 1.000000\n",
      "argmax is 2\n",
      "\n",
      "We ought to choose attribute Semester at this step, and infoGain = 1.000000\n",
      "\n",
      "depth is 3\n",
      "[array(['N', 'A', 'N', 1, 30, 'H'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 3\n",
      "[array(['E', 'A', 'N', 2, 30, 'L'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['E', 'A', 'N', 2, 40, 'L'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'B', 'N', 2, 50, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 1\n",
      "[array(['N', 'D', 'D', 2, 20, 'H'], dtype=object), array(['N', 'B', 'D', 2, 50, 'L'], dtype=object), array(['N', 'A', 'D', 2, 10, 'L'], dtype=object), array(['E', 'D', 'D', 1, 10, 'L'], dtype=object), array(['E', 'B', 'D', 1, 50, 'H'], dtype=object)]\n",
      "Entropy before is 0.970951\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2], [10, 20, 30, 40, 50]]\n",
      "Information Gain is 0.019973\n",
      "Information Gain is 0.170951\n",
      "Information Gain is 0.019973\n",
      "Information Gain is 0.970951\n",
      "argmax is 3\n",
      "\n",
      "We ought to choose attribute ClassSize at this step, and infoGain = 0.970951\n",
      "\n",
      "depth is 2\n",
      "[array(['N', 'A', 'D', 2, 10, 'L'], dtype=object), array(['E', 'D', 'D', 1, 10, 'L'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'D', 'D', 2, 20, 'H'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'B', 'D', 2, 50, 'L'], dtype=object), array(['E', 'B', 'D', 1, 50, 'H'], dtype=object)]\n",
      "Entropy before is 1.000000\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2]]\n",
      "Information Gain is 1.000000\n",
      "Information Gain is 1.000000\n",
      "Information Gain is 1.000000\n",
      "argmax is 2\n",
      "\n",
      "We ought to choose attribute Semester at this step, and infoGain = 1.000000\n",
      "\n",
      "depth is 3\n",
      "[array(['E', 'B', 'D', 1, 50, 'H'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 3\n",
      "[array(['N', 'B', 'D', 2, 50, 'L'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 1\n",
      "[array(['N', 'B', 'A', 2, 40, 'M'], dtype=object), array(['E', 'B', 'A', 2, 30, 'M'], dtype=object), array(['E', 'D', 'A', 2, 50, 'H'], dtype=object), array(['N', 'D', 'A', 1, 10, 'M'], dtype=object)]\n",
      "Entropy before is 0.811278\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2], [10, 20, 30, 40, 50]]\n",
      "Information Gain is 0.311278\n",
      "Information Gain is 0.811278\n",
      "Information Gain is 0.122556\n",
      "Information Gain is 0.811278\n",
      "argmax is 3\n",
      "\n",
      "We ought to choose attribute ClassSize at this step, and infoGain = 0.811278\n",
      "\n",
      "depth is 2\n",
      "[array(['N', 'D', 'A', 1, 10, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['E', 'B', 'A', 2, 30, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'B', 'A', 2, 40, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['E', 'D', 'A', 2, 50, 'H'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 1\n",
      "[array(['N', 'D', 'P', 2, 20, 'M'], dtype=object), array(['N', 'D', 'P', 2, 30, 'H'], dtype=object), array(['N', 'D', 'P', 2, 20, 'M'], dtype=object), array(['N', 'B', 'P', 2, 40, 'M'], dtype=object), array(['N', 'A', 'P', 1, 20, 'M'], dtype=object)]\n",
      "Entropy before is 0.721928\n",
      "[['N', 'E'], ['A', 'B', 'D'], [1, 2], [10, 20, 30, 40, 50]]\n",
      "Information Gain is 0.000000\n",
      "Information Gain is 0.170951\n",
      "Information Gain is 0.072906\n",
      "Information Gain is 0.721928\n",
      "argmax is 3\n",
      "\n",
      "We ought to choose attribute ClassSize at this step, and infoGain = 0.721928\n",
      "\n",
      "depth is 2\n",
      "[]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'D', 'P', 2, 20, 'M'], dtype=object), array(['N', 'D', 'P', 2, 20, 'M'], dtype=object), array(['N', 'A', 'P', 1, 20, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'D', 'P', 2, 30, 'H'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[array(['N', 'B', 'P', 2, 40, 'M'], dtype=object)]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n",
      "depth is 2\n",
      "[]\n",
      "Entropy before is 0.000000\n",
      "This tree has reached its leaf\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeID3(dataFrame, valueFrame, attributes, 5)\n",
    "#DTID3(dataFrame, valueFrame, attributes, 5)\n",
    "DTC4(dataFrame, valueFrame, attributes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DecisionTreeC45(dataFrame, valueFrame, attributes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
